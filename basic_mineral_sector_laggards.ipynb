{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3cf54b",
   "metadata": {},
   "source": [
    "# A Sector-Conditioned Relative Potential Strategy  \n",
    "## Canadian Basic Materials — A Literate Jupyter Notebook\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Objective:**  \n",
    "Identify Canadian Basic Materials stocks with unrealized upside **conditional on the sector being expected to rise**.\n",
    "\n",
    "**Strategy logic:**\n",
    "\n",
    "1. Forecast next-day prices using an **LSTM**\n",
    "2. Infer **sector direction** from the average forecast\n",
    "3. Select **lagging stocks** whose forecast is below the sector average\n",
    "\n",
    "This notebook interleaves explanation with runnable code.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Imports and Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd0c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from yfinance import EquityQuery\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1cc9d1",
   "metadata": {},
   "source": [
    "## 2. Universe Definition: Canadian Basic Materials\n",
    "\n",
    "We define the investment universe using Yahoo Finance’s screener:\n",
    "- Region: Canada\n",
    "- Sector: Basic Materials\n",
    "- Exchanges: TSX, TSX-V, NEO, CSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca77796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universe size: 1395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ZON.V',\n",
       " 'ZNX.V',\n",
       " 'ZNG.V',\n",
       " 'ZLTO.V',\n",
       " 'ZIGY.CN',\n",
       " 'ZFR.V',\n",
       " 'ZEUS.CN',\n",
       " 'ZCC-H.V',\n",
       " 'ZBNI.V',\n",
       " 'ZAU.V']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ca_basic_materials_symbols(\n",
    "    exchanges=(\"TOR\",\"VAN\",\"CNQ\",\"NEO\"),\n",
    "    page_size=250,\n",
    "    max_pages=50\n",
    "):\n",
    "    q = EquityQuery(\"and\", [\n",
    "        EquityQuery(\"eq\", [\"region\", \"ca\"]),\n",
    "        EquityQuery(\"eq\", [\"sector\", \"Basic Materials\"]),\n",
    "        EquityQuery(\"is-in\", [\"exchange\", *exchanges]),\n",
    "    ])\n",
    "\n",
    "    symbols, offset = [], 0\n",
    "    for _ in range(max_pages):\n",
    "        resp = yf.screen(q, size=page_size, offset=offset)\n",
    "        quotes = resp.get(\"quotes\", []) or resp.get(\"finance\", {}).get(\"result\", [{}])[0].get(\"quotes\", [])\n",
    "        if not quotes:\n",
    "            break\n",
    "        symbols.extend([row[\"symbol\"] for row in quotes if row.get(\"symbol\")])\n",
    "        offset += page_size\n",
    "\n",
    "    return list(dict.fromkeys(symbols))\n",
    "\n",
    "symbols = get_ca_basic_materials_symbols()\n",
    "print(f\"Universe size: {len(symbols)}\")\n",
    "symbols[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c130604",
   "metadata": {},
   "source": [
    "## 3. Download One Year of Price Data\n",
    "\n",
    "We download adjusted close prices for the past year and normalize them into\n",
    "a long-format DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae3ff7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>A-H.V</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>A-H.V</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-29</td>\n",
       "      <td>A-H.V</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>A-H.V</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>A-H.V</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date ticker  Close\n",
       "0 2025-01-27  A-H.V    0.4\n",
       "1 2025-01-28  A-H.V    0.4\n",
       "2 2025-01-29  A-H.V    0.4\n",
       "3 2025-01-30  A-H.V    0.4\n",
       "4 2025-01-31  A-H.V    0.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = (pd.Timestamp.today() - pd.DateOffset(months=12)).strftime(\"%Y-%m-%d\")\n",
    "end   = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "raw = yf.download(\n",
    "    tickers=symbols,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    auto_adjust=True,\n",
    "    group_by=\"column\",\n",
    "    progress=False\n",
    ")\n",
    "\n",
    "\n",
    "def to_prices_long(raw_df):\n",
    "    raw_df.index.name = \"Date\"\n",
    "\n",
    "    if isinstance(raw_df.columns, pd.MultiIndex):\n",
    "        close = raw_df[\"Close\"]\n",
    "    else:\n",
    "        close = raw_df[[\"Close\"]]\n",
    "\n",
    "    return (\n",
    "        close.reset_index()\n",
    "             .melt(id_vars=\"Date\", var_name=\"ticker\", value_name=\"Close\")\n",
    "             .dropna()\n",
    "    )\n",
    "\n",
    "prices_long = to_prices_long(raw)\n",
    "prices_long.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688a459",
   "metadata": {},
   "source": [
    "## 4. Modeling Philosophy\n",
    "\n",
    "We forecast **prices**, not returns, using an LSTM.  \n",
    "Cross-sectional logic is applied **after** forecasting.\n",
    "\n",
    "The model learns temporal structure; relative value logic handles selection.\n",
    "\n",
    "## 5. LSTM Architecture\n",
    "\n",
    "An LSTM processes sequential price data and maintains an internal memory,\n",
    "allowing it to capture momentum, regime, and mean-reversion dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d07009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1D(nn.Module):\n",
    "    def __init__(self, hidden=64, layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1]).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d125063",
   "metadata": {},
   "source": [
    "## 6. Sequence Construction\n",
    "\n",
    "Each observation uses the **previous 30 trading days** to predict the next day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a37fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 30\n",
    "HORIZON = 1\n",
    "\n",
    "def make_sequences(df):\n",
    "    X, y, dates, tickers = [], [], [], []\n",
    "\n",
    "    for tkr, g in df.groupby(\"ticker\"):\n",
    "        g = g.sort_values(\"Date\")\n",
    "        s = g[\"Close_s\"].values\n",
    "        d = g[\"Date\"].values\n",
    "\n",
    "        if len(s) < SEQ_LEN + HORIZON:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(s) - SEQ_LEN):\n",
    "            X.append(s[i:i+SEQ_LEN])\n",
    "            y.append(s[i+SEQ_LEN])\n",
    "            dates.append(d[i+SEQ_LEN])\n",
    "            tickers.append(tkr)\n",
    "\n",
    "    return (\n",
    "        np.array(X)[..., None].astype(np.float32),\n",
    "        np.array(y).astype(np.float32),\n",
    "        np.array(dates),\n",
    "        np.array(tickers),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55cb5c",
   "metadata": {},
   "source": [
    "## 7. Time-Based Train / Test Split\n",
    "\n",
    "We train on ~11 months and evaluate on the most recent month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7d0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_long[\"Date\"] = pd.to_datetime(prices_long[\"Date\"])\n",
    "cutoff = prices_long[\"Date\"].max() - pd.DateOffset(months=1)\n",
    "\n",
    "train_df = prices_long[prices_long[\"Date\"] <= cutoff]\n",
    "test_df  = prices_long[prices_long[\"Date\"] >  cutoff]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1502c",
   "metadata": {},
   "source": [
    "## 8. Scaling (Per Ticker, Train Only)\n",
    "\n",
    "All scaling is done using **training data only** to prevent leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31e117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = (\n",
    "    train_df.groupby(\"ticker\")[\"Close\"]\n",
    "            .agg([\"mean\", \"std\"])\n",
    "            .replace(0, 1)\n",
    ")\n",
    "\n",
    "def scale(df):\n",
    "    df = df.join(scalers, on=\"ticker\")\n",
    "    df[\"Close_s\"] = (df[\"Close\"] - df[\"mean\"]) / df[\"std\"]\n",
    "    return df.dropna()\n",
    "\n",
    "train_s = scale(train_df)\n",
    "test_s  = scale(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a37619",
   "metadata": {},
   "source": [
    "## 9. Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cdd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, *_ = make_sequences(train_s)\n",
    "\n",
    "model = LSTM1D()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "loader = DataLoader(\n",
    "    list(zip(torch.tensor(X_train), torch.tensor(y_train))),\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for epoch in range(10):\n",
    "    for xb, yb in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92695254",
   "metadata": {},
   "source": [
    "## 10. Generate Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f492ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, d_test, t_test = make_sequences(\n",
    "    pd.concat([\n",
    "        train_s.groupby(\"ticker\").tail(SEQ_LEN),\n",
    "        test_s\n",
    "    ])\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    yhat = model(torch.tensor(X_test)).numpy()\n",
    "\n",
    "mu = scalers.loc[t_test, \"mean\"].values\n",
    "sd = scalers.loc[t_test, \"std\"].values\n",
    "\n",
    "y_pred = yhat * sd + mu\n",
    "y_true = y_test * sd + mu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c362b9f6",
   "metadata": {},
   "source": [
    "## 11. Sector Direction Signal\n",
    "\n",
    "We compute predicted returns and take the **cross-sectional average**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d878f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({\n",
    "    \"Date\": pd.to_datetime(d_test),\n",
    "    \"ticker\": t_test,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_true\": y_true\n",
    "}).sort_values([\"ticker\", \"Date\"])\n",
    "\n",
    "preds[\"prev_close\"] = preds.groupby(\"ticker\")[\"y_true\"].shift(1)\n",
    "preds[\"pred_ret\"] = (preds[\"y_pred\"] - preds[\"prev_close\"]) / preds[\"prev_close\"]\n",
    "preds = preds.dropna()\n",
    "\n",
    "preds[\"sector_avg_pred_ret\"] = preds.groupby(\"Date\")[\"pred_ret\"].transform(\"mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250839fd",
   "metadata": {},
   "source": [
    "## 12. Relative Potential Signal\n",
    "\n",
    "A stock’s **relative gap** measures how far below the sector average it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2baf6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"rel_gap\"] = preds[\"pred_ret\"] - preds[\"sector_avg_pred_ret\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b00564",
   "metadata": {},
   "source": [
    "## 13. Surface Laggards When Sector Is Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ef5413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>pred_ret</th>\n",
       "      <th>rel_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, ticker, pred_ret, rel_gap]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laggards = (\n",
    "    preds[preds[\"sector_avg_pred_ret\"] > 0]\n",
    "        .sort_values(\"rel_gap\")\n",
    "        .groupby(\"Date\")\n",
    "        .head(10)\n",
    ")\n",
    "\n",
    "laggards[[\"Date\", \"ticker\", \"pred_ret\", \"rel_gap\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a06296",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No laggards found. Ensure the previous cell ran successfully.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlaggards\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m laggards\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo laggards found. Ensure the previous cell ran successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# --- Per-day comparison ---\u001b[39;00m\n\u001b[1;32m      5\u001b[0m laggards_vs_sector_daily \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     laggards\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No laggards found. Ensure the previous cell ran successfully."
     ]
    }
   ],
   "source": [
    "if \"laggards\" not in globals() or laggards.empty:\n",
    "    raise RuntimeError(\"No laggards found. Ensure the previous cell ran successfully.\")\n",
    "\n",
    "# --- Per-day comparison ---\n",
    "laggards_vs_sector_daily = (\n",
    "    laggards\n",
    "    .groupby(\"Date\")\n",
    "    .agg(\n",
    "        laggards_avg_pred_ret=(\"pred_ret\", \"mean\"),\n",
    "        sector_avg_pred_ret=(\"sector_avg_pred_ret\", \"mean\"),\n",
    "        n_laggards=(\"ticker\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "laggards_vs_sector_daily[\"gap_laggards_vs_sector\"] = (\n",
    "    laggards_vs_sector_daily[\"laggards_avg_pred_ret\"]\n",
    "    - laggards_vs_sector_daily[\"sector_avg_pred_ret\"]\n",
    ")\n",
    "\n",
    "print(\"Per-day comparison (laggards vs sector average):\")\n",
    "display(laggards_vs_sector_daily.head(10))\n",
    "\n",
    "\n",
    "# --- Aggregate summary across the test period ---\n",
    "summary = laggards_vs_sector_daily.agg({\n",
    "    \"laggards_avg_pred_ret\": [\"mean\", \"median\"],\n",
    "    \"sector_avg_pred_ret\": [\"mean\", \"median\"],\n",
    "    \"gap_laggards_vs_sector\": [\"mean\", \"median\"],\n",
    "    \"n_laggards\": \"mean\",\n",
    "})\n",
    "\n",
    "summary.index = [\"_\".join(col).strip() for col in summary.index.to_flat_index()]\n",
    "\n",
    "print(\"\\nAggregate summary across test period:\")\n",
    "display(summary.to_frame(name=\"value\"))\n",
    "\n",
    "\n",
    "# --- Sanity check: how often are laggards actually below the sector average? ---\n",
    "sanity = (\n",
    "    laggards\n",
    "    .assign(below_sector = laggards[\"pred_ret\"] < laggards[\"sector_avg_pred_ret\"])\n",
    "    .groupby(\"Date\")[\"below_sector\"]\n",
    "    .mean()\n",
    "    .rename(\"pct_laggards_below_sector\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nSanity check: % of selected laggards actually below sector average:\")\n",
    "display(sanity.head(10))\n",
    "\n",
    "\n",
    "# --- Final scalar you can quote ---\n",
    "avg_gap = laggards_vs_sector_daily[\"gap_laggards_vs_sector\"].mean()\n",
    "\n",
    "print(\n",
    "    f\"\\nOn average, selected laggards are \"\n",
    "    f\"{avg_gap:.4%} BELOW the sector's predicted return \"\n",
    "    f\"on days when the sector trend is positive.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3818c50",
   "metadata": {},
   "source": [
    "## 14. Interpretation\n",
    "\n",
    "- Sector average > 0 → **risk-on regime**\n",
    "- Negative relative gap → **has not caught up**\n",
    "- Strategy exploits **cross-sectional convergence**, not perfect prediction\n",
    "\n",
    "The model only needs to be directionally consistent across the group.\n",
    "\n",
    "## 15. Summary\n",
    "\n",
    "This notebook demonstrates a complete pipeline:\n",
    "- LSTM-based price forecasting\n",
    "- Sector-level regime detection\n",
    "- Relative-value stock selection\n",
    "\n",
    "> The key insight: *When the sector is expected to rise, laggards are potential opportunities.*\n",
    "\n",
    "Extensions include:\n",
    "- volatility normalization\n",
    "- transaction cost modeling\n",
    "- long–short portfolios\n",
    "- rolling backtests\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
